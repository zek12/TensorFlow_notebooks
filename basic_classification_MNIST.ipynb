{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBLHIB87lN95"
      },
      "source": [
        "# Basic Classification with MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbtyrEoPlN97"
      },
      "source": [
        "In this tutorial, we are going to use the dataset MNIST, from Keras. This dataset is composed of 70,000 pictures of 28x28 pixels, in grayscale (each pixel taking values between 0-255), of digits (between 0 and 9) written by hand. The dataset is split into a training set (composed of 60,000 samples) and a test set (composed of 10,000 samples)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qnt3zJ9lN99"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCBIult_lN9-"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIxRy6SSlN9_"
      },
      "source": [
        "We can print the 8th image of the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "oG2Q3RJWlN-A",
        "outputId": "88dc59ec-1c9c-43be-d7dc-1543983ce4dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f27cbbe9310>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[8], cmap = plt.cm.binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqzp2ApKlN-B"
      },
      "source": [
        "... and its corresponding label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmmb9WQQlN-C",
        "outputId": "0b91f902-c32c-415a-aea6-e1cd603ae516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "print(y_train[8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPMVpGFblN-D"
      },
      "source": [
        "The training set is formed by 60,000 pictures of 28x28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obweQWeIlN-E",
        "outputId": "87134740-7f4a-4810-8478-3df9d11f01a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "(60000, 28, 28)\n",
            "uint8\n"
          ]
        }
      ],
      "source": [
        "print(x_train.ndim)\n",
        "print(x_train.shape)\n",
        "print(x_train.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz_S6H46lN-F"
      },
      "source": [
        "The test set is formed by 10,000 pictures of 28x28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saPTeEollN-F",
        "outputId": "3e8c2b79-aa02-486a-910f-ea5c94c4e08c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "(10000, 28, 28)\n",
            "uint8\n"
          ]
        }
      ],
      "source": [
        "print(x_test.ndim)\n",
        "print(x_test.shape)\n",
        "print(x_test.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgfX4h48lN-G"
      },
      "source": [
        "We can slice our data, for example take the first 100 pictures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erzuxj0xlN-H",
        "outputId": "b089b288-ccf5-4ea0-a6d6-9fa85c00c6bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(99, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "my_slice = x_train[1:100:, :]\n",
        "print(my_slice.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xag6qsV-lN-I"
      },
      "source": [
        "Another way of doing the same:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpg9iQzJlN-J",
        "outputId": "fa9ee29b-bb97-4946-c7d4-7d31a0a8791d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(99, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "my_slice = x_train[1:100, 0:28, 0:28]\n",
        "print(my_slice.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvJjMQRUlN-K"
      },
      "source": [
        "If we want to select the 14x14 pixels in the bottom-right corner of all pictures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pue_pGmwlN-L",
        "outputId": "3e98d693-eebc-4a07-e909-f920586411ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 14, 14)\n"
          ]
        }
      ],
      "source": [
        "my_slice = x_train[:, 14:, 14:]\n",
        "print(my_slice.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uHMOZLelN-N"
      },
      "source": [
        "And if we want to select the 14x14 pixels in the centre of all pictures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eREpFPBNlN-O",
        "outputId": "f749cec6-8d07-4eb9-fc47-cecc192cb657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 14, 14)\n"
          ]
        }
      ],
      "source": [
        "my_slice = x_train[:, 7:-7, 7:-7]\n",
        "print(my_slice.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing of input data"
      ],
      "metadata": {
        "id": "t_TA52qhl8Ju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each image in our input data consists of 28x28 pixels, each taking values between [0-255]. It's convenient to scale the pixels in a range [0-1], aka **normalization**, because this helps the training process to converge. Furthermore, in a neural network, we don't use values that are mich higher than the weights in the network, or data with heterogenous values between themselves."
      ],
      "metadata": {
        "id": "Mdoy7ANqmLV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "id": "mZYoviCcmKhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another useful transformation is **re-shaping** of data, i.e. instead of having a vector of matrices (each of 28x28 pixels), we can have a vector of vectors of length 28x28. This is because this is the format that a neural network accepts as input."
      ],
      "metadata": {
        "id": "GaDVJqInnZCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQn2b2aon_HH",
        "outputId": "11db962f-c409-4a92-9623-2779fd612fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)"
      ],
      "metadata": {
        "id": "E9zuyLJcl_ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXpTHLemoU6_",
        "outputId": "5c487cdf-01ed-4064-944b-ff7ddd65a8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can perform **one-hot encoding** on the labels (`y_train` and `y_test`)."
      ],
      "metadata": {
        "id": "sFDT31Bso8yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Wg2HcWlYpUo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[0])\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp39mxn_phg3",
        "outputId": "8164100c-9993-43d8-ea13-72b704506367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edkwTLIkpwwQ",
        "outputId": "eb01b879-7fd6-45dc-bde3-22fde8af1243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, num_classes = 10)\n",
        "y_test = to_categorical(y_test, num_classes = 10)"
      ],
      "metadata": {
        "id": "uX98fUQLqJ6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[0])\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rsrpo6JqVNZ",
        "outputId": "5fc3b74a-c3a1-4ac1-d18a-e041c0d19721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s-_YmxKqYra",
        "outputId": "6081e7d1-f386-4d21-c2ce-b5ca128d1a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have the data in the format that we need in order to train our neural network."
      ],
      "metadata": {
        "id": "9GWfSbjUqeGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling"
      ],
      "metadata": {
        "id": "enK7C5Bsqklz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our example, we will use class `Sequential`, which defines our model as a sequence of layers. Each layer will distill the input data to obtain the desired output.\n",
        "\n",
        "Keras offers an API to define more complex models; more information in https://keras.io/guides/functional_api/."
      ],
      "metadata": {
        "id": "U57LyN5Hql8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "YxRHlLI0uZL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(10, activation = 'sigmoid', input_shape = (784,)))\n",
        "model.add(Dense(10, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "AoIpZeJ4t9dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we defined our model as a neural network with 2 layers (1 input and 1 output layer) with 10 neurons each, densely connected."
      ],
      "metadata": {
        "id": "jHBKCNyau4FE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJTTJp3ZvlPy",
        "outputId": "21f6c2dd-6e71-43b7-9634-3adfb2cffa8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,960\n",
            "Trainable params: 7,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the first layer has a total of 7850 parameters: these correspond to 784 input pixels * 10 input neurons = 7840 + 1 input bias in each neuron = **7850**.\n",
        "\n",
        "The second layer has 110 parameters, which correspond to 10 outputs from first layer * 10 neurons in the second layer + 10 input biases in each neuron = **110**.\n",
        "\n",
        "The sum of 7850 + 110 = **7960**."
      ],
      "metadata": {
        "id": "VNTvjdsNwUTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could also define initialization values to the weights of the nodes. This can be specified as an argument in `Dense()` function. More information in https://keras.io/api/layers/initializers/#usage-of-initializers."
      ],
      "metadata": {
        "id": "sDpTiP4UxcPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure the training process"
      ],
      "metadata": {
        "id": "k0iOL-9G7yxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we can start training our model, we need to configure the training process with the `compile()` method.\n",
        "\n",
        "In particular, we need to specify the following arguments:\n",
        "- **loss**: this is the loss function, which will evaluate the degree of error between actual and predicted labels.\n",
        "- **optimizer**: this is how the model is updated based on the data it sees and its loss function. In this example, we will use `stochastic gradient descent` (sgd).\n",
        "- **metrics**: this is the metric to monitor the training and testing process. In this example, we will use `accuracy`."
      ],
      "metadata": {
        "id": "-yXkDQe_71Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = \"sgd\",\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "J58e35tYzDSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "PPF0GJ9j-R6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhvO9hf9-VD-",
        "outputId": "eaaa3e2e-1a52-48b6-e288-7561304bcfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.9365 - accuracy: 0.4737\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 1.3240 - accuracy: 0.7135\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.9864 - accuracy: 0.7939\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7972 - accuracy: 0.8322\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6793 - accuracy: 0.8523\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f27cbb5a0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This trains the model in 5 iterations (epochs).\n",
        "\n",
        "Intuitively, in each iteration, the model applies the optimizer algorithm to re-calculate the weights to try to minimize the loss function."
      ],
      "metadata": {
        "id": "_0eKlAIf_SQH"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 ('my-env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a0a8ca85be464c3bfb7d548956977679826247d99e80b1da5a6b196384cfb5ac"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}